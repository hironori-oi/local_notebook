# ===========================================
# NotebookLM Local App - Environment Variables
# ===========================================
# Copy this file to .env and update the values
# cp .env.example .env

# ===========================================
# Environment Mode
# ===========================================
# "development" or "production"
# In production mode:
# - JWT_SECRET_KEY validation is strict
# - Swagger docs are disabled
# - Logging level is INFO (not DEBUG)
ENV=development

# ===========================================
# Database (PostgreSQL with pgvector)
# ===========================================
# For Docker Compose (uses service name):
DATABASE_URL=postgresql://notebooklm:notebooklm_password@postgres:5432/notebooklm

# Docker Compose specific
POSTGRES_USER=notebooklm
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_DB=notebooklm

# ===========================================
# LLM Provider Configuration
# ===========================================
# Provider: "ollama" or "vllm"
LLM_PROVIDER=ollama

# Ollama Configuration (native API at /api/chat)
LLM_API_BASE=http://localhost:11434
LLM_MODEL=llama3.1:8b
# Timeout in seconds for LLM requests
LLM_TIMEOUT=120

# For vLLM:
# LLM_API_BASE=http://vllm-server:8000/v1
# LLM_MODEL=your-vllm-model

# ===========================================
# Generation LLM Configuration (Infographic/Slides)
# ===========================================
# Separate model for infographic and slide generation
# If not set, uses LLM_MODEL above
GENERATION_LLM_MODEL=
GENERATION_LLM_MAX_TOKENS=8192

# ===========================================
# Embedding Configuration
# ===========================================
EMBEDDING_API_BASE=http://localhost:11434
EMBEDDING_MODEL=nomic-embed-text
# Embedding dimensions (depends on model)
# nomic-embed-text: 768
# text-embedding-3-small: 1536
EMBEDDING_DIM=768
# Timeout in seconds for embedding requests
EMBEDDING_TIMEOUT=60

# ===========================================
# Authentication
# ===========================================
# IMPORTANT: Generate a secure secret key for production!
# Run: python -c "import secrets; print(secrets.token_hex(32))"
# In production, this MUST be at least 32 characters
JWT_SECRET_KEY=CHANGE_ME_TO_RANDOM_SECRET_KEY

JWT_ALGORITHM=HS256
# Token expiration in minutes (default: 24 hours = 1440 minutes)
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=1440

# ===========================================
# Rate Limiting
# ===========================================
# Authentication endpoints (stricter to prevent brute force)
RATE_LIMIT_AUTH_REQUESTS=5
RATE_LIMIT_AUTH_WINDOW=900

# General API endpoints
RATE_LIMIT_API_REQUESTS=100
RATE_LIMIT_API_WINDOW=60

# ===========================================
# CORS Configuration
# ===========================================
# Comma-separated list of allowed origins
# For production, set to your actual frontend URL
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# ===========================================
# Application Settings
# ===========================================
# Upload directory for source files
UPLOAD_DIR=data/uploads
# Maximum file size in MB
MAX_UPLOAD_SIZE_MB=50

# ===========================================
# Janus Image Generation Configuration (Dedicated Server)
# ===========================================
# Janus-Pro-7B server API base URL
JANUS_API_BASE=http://localhost:9000
# Timeout for image generation (seconds) - generation takes 30-120s
JANUS_TIMEOUT=180
# Enable/disable image generation
JANUS_ENABLED=true
# Image dimensions (384x384 for Janus-Pro-7B)
JANUS_INFOGRAPHIC_WIDTH=384
JANUS_INFOGRAPHIC_HEIGHT=384
JANUS_SLIDE_WIDTH=384
JANUS_SLIDE_HEIGHT=384
# CFG weight for image generation
JANUS_CFG_WEIGHT=5.0
# Temperature for image generation
JANUS_TEMPERATURE=1.0

# ===========================================
# Frontend Configuration
# ===========================================
# Backend API URL (for frontend to call)
NEXT_PUBLIC_API_BASE_URL=http://localhost:8000
